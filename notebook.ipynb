{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A CLASSIFICATION PROJECT - CUSTOMER CHURN ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROJECT SCENARIO\n",
    "As a data scientist at Vodafone Corporation, a large telecommunication company.\n",
    "* Vodafone want to find the likelihood of a customer leaving the organization, the key indicators of churn as well as the retention strategies that can be implemented to avert this problem.\n",
    "* To do this, the business development unit has provided you with data to build a series of machine learning models to predict customer churn.\n",
    "* The marketing and sales team as well have provided you with some data to aid this endeavor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROJECT DESCRIPTION\n",
    " Telecommunication companies face the ongoing challenge of customer churn, where subscribers discontinue services and switch to competitors. \n",
    " To address this issue and proactively retain customers, we are undertaking a customer churn analysis project utilizing machine learning techniques. \n",
    " In this project, we explore how machine learning techniques can be leveraged for customer churn analysis in telecommunication networks, following the well-established CRISP-DM (Cross-Industry Standard Process for Data Mining) framework. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUSINESS UNDERSTANDING\n",
    "In today's highly competitive telecommunication industry, customer churn, or the loss of customers to competitors, poses a significant challenge for companies striving to maintain market share and profitability. \n",
    "Identifying customers at risk of churn and implementing proactive retention strategies is crucial for sustaining business growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HYPOTHESIS\n",
    "NULL HYPOTHESIS: There is no relationship between the tenure and the churn of customers.\n",
    "\n",
    "ALTERNATE HYPOTHESIS: There is a relationship between the tenure and the churn of customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANALYTICAL QUESTIONS\n",
    "1. What is the overall churn rate of the telecommunication company?\n",
    "2. Does churn rate differ based on the payment method?\n",
    "3. What is the churn rate of customers based on their seniority?\n",
    "4. What is the churn rate of customers based on their monthlycharges?\n",
    "5. What is the churn rate of customers based on their contract type?\n",
    "6. What is the churn rate of customers based on their gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyodbc\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import dotenv_values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "#Machine Learning Packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Loading first dataset from database\n",
    "# Load environment variables from .env file\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Access database credentials from environment variables dictionary\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "password = environment_variables.get(\"PASSWORD\")\n",
    "username = environment_variables.get(\"USERNAME\")\n",
    "\n",
    "# Construct the connection string\n",
    "connection_string = f\"DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};User Id={username};PASSWORD={password};\"\n",
    "\n",
    "print(\"USERNAME:\", username)\n",
    "\n",
    "# Construct the connection string\n",
    "connection_string = f\"DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};UID={username};PWD={password};\"\n",
    "# Connect to the database\n",
    "try:\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# Specify the SQL queries to extract data from the tables\n",
    "Dataset1 = \"SELECT * FROM dbo.LP2_Telco_churn_first_3000\"\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a cursor from the connection\n",
    "with connection.cursor() as cursor:\n",
    "    # Execute the queries and fetch data into Pandas DataFrames\n",
    "    Dataset1 = pd.read_sql_query(Dataset1, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Preview the first dataset\n",
    "Dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Load the second the dataset\n",
    "Dataset2 = pd.read_csv(\"./Dataset/LP2_Telco-churn-second-2000.csv\")\n",
    "Dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the columns\n",
    "column_names = Dataset1.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the columns\n",
    "column_names = Dataset2.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the number of rows and columns\n",
    "Dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the number of rows and columns\n",
    "Dataset2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. The outputs show both datasets have the same column names and number of columns so they can be merged easily.\n",
    "2. However, some of the column names are in upper case so they will be converted to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert column names to lower case\n",
    "Dataset1.columns = Dataset1.columns.str.lower()\n",
    "\n",
    "#Check the columns to confirm\n",
    "column_names = Dataset1.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert column names to lower case\n",
    "Dataset2.columns = Dataset2.columns.str.lower()\n",
    "\n",
    "#Check the columns to confirm\n",
    "column_names = Dataset2.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check cell values\n",
    "Dataset1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows there are empty cells in these columns; multiplelines, onlinesecurity, onlinebackup, deviceprotection, techsupport, streamingtv, streamingmovies, totalcharges and churn. They will be treated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check cell values\n",
    "Dataset2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows there are no empty cells in any of the columns but some of the columns have the wrong datatype. This will be taken care of accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check for the unique values of each column\n",
    "def check_unique_values(df):\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "\n",
    "#Check for Dataset1\n",
    "check_unique_values(Dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def check_unique_values(df):\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "\n",
    "#Check for Dataset2\n",
    "check_unique_values(Dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 'True' and 'False' values in the first dataset will be replaced with 'Yes' and 'No' to ensure both datasets have the same values before they are merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Replace the \"True\" and \"False\" values in Dataset1\n",
    "def replace_true_false(df):\n",
    "    df.replace({True: 'Yes', False: 'No'}, inplace=True)\n",
    "\n",
    "replace_true_false(Dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check Dataset1 to confirm\n",
    "Dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Replace the values in seniorcitizen column\n",
    "def replace_yes_no_with_1_0(df):\n",
    "    df['seniorcitizen'] = df['seniorcitizen'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "replace_yes_no_with_1_0(Dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check Dataset1 to confirm\n",
    "Dataset1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since the columns and values for both datasets are similar now, we will merge both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Merge both datasets\n",
    "df = pd.concat([Dataset1, Dataset2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check merged dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check cell values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 'totalcharges' column has the wrong datatype. It will be converted into a float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert 'totalcharges' column to numeric (float)\n",
    "df['totalcharges'] = pd.to_numeric(df['totalcharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check cell values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def check_unique_values(df):\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "\n",
    "#Check for Dataset2\n",
    "check_unique_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "#List of categorical columns\n",
    "categorical_columns = ['gender', 'partner', 'dependents', 'phoneservice', 'multiplelines', \n",
    "                       'internetservice', 'onlinesecurity', 'onlinebackup', 'deviceprotection', \n",
    "                       'techsupport', 'streamingtv', 'streamingmovies', 'contract', \n",
    "                       'paperlessbilling', 'paymentmethod', 'churn']\n",
    "\n",
    "#Set up the figure and axes for plotting\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(18, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "#Loop through each categorical column and plot the frequency of each category\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    #Check for duplicate labels and drop them\n",
    "    unique_values = df[column].unique()\n",
    "    if len(unique_values) != df[column].nunique():\n",
    "        df_unique = df.drop_duplicates(subset=column)\n",
    "        sns.countplot(x=column, data=df_unique, ax=axes[i])\n",
    "    else:\n",
    "        sns.countplot(x=column, data=df, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "#Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#List of numerical columns\n",
    "numerical_columns = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "\n",
    "#Set up the figure and axes for plotting\n",
    "fig, axes = plt.subplots(nrows=len(numerical_columns), ncols=1, figsize=(8, 5*len(numerical_columns)))\n",
    "\n",
    "#Loop through each numerical column and plot its histogram\n",
    "for i, column in enumerate(numerical_columns):\n",
    "    df[column].hist(ax=axes[i], bins=20, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "#Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Boolean variable to analyze\n",
    "boolean_variable = 'seniorcitizen'\n",
    "\n",
    "#Calculate the proportion of 'True' and 'False' values\n",
    "proportion_true = df[boolean_variable].sum() / len(df)\n",
    "proportion_false = 1 - proportion_true\n",
    "\n",
    "#Plot the proportions\n",
    "sns.barplot(x=['True', 'False'], y=[proportion_true, proportion_false])\n",
    "plt.title(f'Proportion of True and False values in {boolean_variable}')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check summary statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "1. The 'seniorcitizen', 'tenure' and 'monthlycharges' columns do not have any missing values but the 'totalcharges' column has missing values.\n",
    "2. The average monthlycharge is approximately 65.09, the minimum monthlycharge is approximately 18.4 and the maximum monthlycharge is approximately 118.65. \n",
    "3. In the 'tenure' column, the standard deviation is approximately 24.53, indicating that the values are spread out over a wide range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check 'tenure' \n",
    "numerical_column = ['tenure']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[numerical_column])\n",
    "plt.title('Box Plot of Tenure')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check 'monthlycharges' \n",
    "numerical_column = ['monthlycharges']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[numerical_column])\n",
    "plt.title('Box Plot of MonthlyCharges')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check 'totalcharges' \n",
    "numerical_column = ['totalcharges']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[numerical_column])\n",
    "plt.title('Box Plot of TotalCharges')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "1. This shows all the columns do not have any outliers.\n",
    "2. The 'tenure' boxplot suggests a fairly even distribution of tenure values across the dataset.\n",
    "3. The 'monthlycharges' boxplot suggests that most customers have monthly charges clustered around the median, with a fairly consistent spread across the quartiles.\n",
    "4. The 'totalcharges' values are concentrated between approximately 2000 and 4000, with the median closer to Q3, suggesting a skew towards higher charges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gender Vrs Churn Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Get the count of churn for each gender\n",
    "gender_churn_counts = df.groupby(['gender', 'churn']).size().unstack(fill_value=0)\n",
    "\n",
    "print(gender_churn_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Plot Gender vs. Churn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='gender', hue='churn', data=df)\n",
    "plt.title('Gender vs. Churn')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Churn', labels=['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This implies that among females, 1823 customers did not churn, and 661 customers did churn. Similarly, among males, 1883 customers did not churn, and 675 customers did churn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Select the relevant columns\n",
    "selected_columns = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "selected_corr_matrix = df[selected_columns].corr()\n",
    "\n",
    "#Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(selected_corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Heatmap of Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. Tenure vs. Monthly Charges: Thereâ€™s a weak positive correlation of (0.24), suggesting that as tenure increases, monthly charges tend to increase slightly.\n",
    "2. Tenure vs. Total Charges: A strong positive correlation of (0.83) is observed here, indicating that longer tenure is strongly associated with higher total charges.\n",
    "3. Monthly Charges vs. Total Charges: This pair shows a moderate positive correlation of (0.65), meaning as monthly charges increase, total charges also tend to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contract Vrs Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "contract_churn_counts = df.groupby(['contract', 'churn']).size()\n",
    "print(contract_churn_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='contract', hue='churn', data=df)\n",
    "plt.title('Contract vs. Churn')\n",
    "plt.xlabel('Contract')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Churn', loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. For customers with a 'Month-to-month' contract, there are 1560 customers who did not churn (No) and 1184 customers who did churn (Yes).\n",
    "2. For customers with a 'One year' contract, there are 933 customers who did not churn and 122 customers who did churn.\n",
    "3. For customers with a 'Two year' contract, there are 1213 customers who did not churn and 30 customers who did churn.\n",
    "4. It can be concluded that customers with shorter-term contracts (like 'Month-to-month') tend to churn more compared to those with longer-term contracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 'churn' column contains string values ('Yes' and 'No'), which cannot be converted to float for correlation calculation. To perform correlation analysis, we need to encode these categorical values into numerical values first. One common approach is to use label encoding, where 'Yes' is replaced with 1 and 'No' is replaced with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#Encode the 'churn' column\n",
    "df['churn_encoded'] = label_encoder.fit_transform(df['churn'])\n",
    "\n",
    "#Calculate correlation matrix\n",
    "correlation_matrix = df[['tenure', 'monthlycharges', 'totalcharges', 'churn_encoded']].corr()\n",
    "\n",
    "#Display correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. tenure vs. monthlycharges: There is a positive correlation of approximately 0.24, indicating that as tenure increases, monthly charges also tend to increase, but the correlation is not very strong.\n",
    "2. tenure vs. totalcharges: There is a strong positive correlation of approximately 0.83, suggesting that as tenure increases, total charges also increase.\n",
    "3. tenure vs. churn_encoded: There is a negative correlation of approximately -0.35, indicating that as tenure increases, the likelihood of churn decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPOTHESIS TESTING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null Hypothesis: There is no relationship between the tenure and the churn of customers.\n",
    "Alternate Hypothesis: There is a relationship between the tenure and the churn of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Create a contingency table\n",
    "contingency_table = pd.crosstab(df['tenure'], df['churn'])\n",
    "\n",
    "#Perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "#Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"P-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "\n",
    "#Compare p-value with alpha to make a decision\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a relationship between tenure and churn.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no relationship between tenure and churn.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on the p-value (which is far below the significance level of 0.05), we reject the null hypothesis. This means that there is sufficient evidence to conclude that there is a statistically significant relationship between tenure and churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWERING THE ANALYTICAL QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the overall churn rate against retained customers?\n",
    "2. Does churn rate differ based on the payment method?\n",
    "3. What is the churn rate of customers based on their seniority?\n",
    "4. What is the churn rate of customers based on their monthlycharges?\n",
    "5. What is the churn rate of customers based on their contract type?\n",
    "6. What is the churn rate of customers based on their gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question One: What is the overall churn rate against retained customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Count the number of customers who churned\n",
    "churned_count = df['churn'].value_counts()['Yes']\n",
    "\n",
    "#Calculate the total number of customers\n",
    "total_customers = len(df)\n",
    "\n",
    "#Calculate the overall churn rate\n",
    "overall_churn_rate = (churned_count / total_customers) * 100\n",
    "\n",
    "print(\"Overall churn rate:\", overall_churn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Calculate the churn rates as percentages\n",
    "churn_rate_percentage = (churned_count / total_customers) * 100\n",
    "retention_rate_percentage = 100 - churn_rate_percentage\n",
    "\n",
    "#Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar([\"Churned\", \"Retained\"], [churn_rate_percentage, retention_rate_percentage], color=['orange', 'skyblue'])\n",
    "plt.title(\"Overall Churn Rate\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "#Show the percentages on the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, f\"{yval:.2f}%\", va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows a bar plot with two bars: one for the churned customers and one for the retained customers. It shows there are more retained customers than customers that churned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Two: Does churn rate differ based on the payment method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Calculate churn rate for each payment method\n",
    "payment_churn_rates = df.groupby('paymentmethod')['churn'].value_counts(normalize=True).loc[:, 'Yes'] * 100\n",
    "\n",
    "# Plot churn rate based on payment method\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = payment_churn_rates.plot(kind='bar', color='skyblue')\n",
    "plt.title('Churn Rate by Payment Method')\n",
    "plt.xlabel('Payment Method')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "#Add labels on top of each bar\n",
    "for i, rate in enumerate(payment_churn_rates):\n",
    "    plt.text(i, rate, f'{rate:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows that customers using electronic check have the highest churn rate, which could suggest issues with this payment method. This might be as a result of user dissatisfaction hence requires further investigation and improvement of the payment process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Three: What is the churn rate of customers based on their Seniority?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculate churn rate based on seniority\n",
    "seniority_churn_rate = df.groupby('seniorcitizen')['churn'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
    "\n",
    "# Plot churn rate based on seniority using a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(seniority_churn_rate, labels=['Senior Citizen' if seniority == 1 else 'Non-Senior Citizen' for seniority in seniority_churn_rate.index], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Churn Rate by Seniority')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Four: What is the churn rate of customers based on their monthlycharges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check unique values in the monthlycharges column\n",
    "unique_monthlycharges = df['monthlycharges'].unique()\n",
    "\n",
    "#Print unique values\n",
    "print(unique_monthlycharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Define bins for monthly charges\n",
    "bins = [0, 30, 60, 90, 120]\n",
    "\n",
    "#Create labels for the bins\n",
    "labels = ['0-30', '30-60', '60-90', '90-120']\n",
    "\n",
    "#Assign each monthly charge to a bin\n",
    "df['monthly_charges_bin'] = pd.cut(df['monthlycharges'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "#Calculate churn rate based on monthly charges\n",
    "monthly_charges_churn_rate = df.groupby('monthly_charges_bin')['churn'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
    "\n",
    "#Plot churn rate based on monthly charges using a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = monthly_charges_churn_rate.plot(kind='bar', color='skyblue')\n",
    "plt.title('Churn Rate by Monthly Charges')\n",
    "plt.xlabel('Monthly Charges')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add labels on the bars\n",
    "for bar in bars.patches:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.5, f'{bar.get_height():.2f}%', ha='center', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This illustrates the relationship between the amount customers are charged monthly and the rate at which they stop using the service (churn rate). \n",
    "0-30 Range: Represents the lowest monthly charges and corresponds to the lowest churn rate, suggesting customers are satisfied with the service or find it affordable.\n",
    "\n",
    "30-60 Range: Shows a significant increase in churn rate, indicating a threshold where customers may begin to consider the service too expensive or not worth the cost.\n",
    "\n",
    "60-90 & 90-120 Ranges: Both have the highest and constant churn rates, suggesting that beyond a certain price point, the churn rate stabilizes, possibly due to a segment of customers who are less price-sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Five: What is the churn rate of customers based on their contract type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Calculate churn rate based on contract type\n",
    "contract_churn_rate = df.groupby('contract')['churn'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
    "\n",
    "#Plot churn rate based on contract type using a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = contract_churn_rate.plot(kind='bar', color='skyblue')\n",
    "plt.title('Churn Rate by Contract Type')\n",
    "plt.xlabel('Contract Type')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "#Add labels on the bars\n",
    "for bar in bars.patches:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.5, f'{bar.get_height():.2f}%', ha='center', color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This compares the churn rates across different contract durations. \n",
    "Month-to-Month: This category has the highest churn rate, around 40%, indicating that customers with no long-term commitments are more likely to discontinue the service.\n",
    "\n",
    "One Year: Shows a significantly lower churn rate of about 12%, suggesting increased customer retention with longer contract terms.\n",
    "\n",
    "Two Years: Has the lowest churn rate, which implies that the longest commitment contracts result in the best customer retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Six: What is the churn rate of customers based on their gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Calculate churn rate based on gender\n",
    "gender_churn_rate = df.groupby('gender')['churn'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
    "\n",
    "#Plot churn rate based on gender using a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = gender_churn_rate.plot(kind='bar', color='skyblue')\n",
    "plt.title('Churn Rate by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "#Add labels on the bars\n",
    "for bar in bars.patches:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.5, f'{bar.get_height():.2f}%', ha='center', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The churn rates are nearly identical for both genders, suggesting that gender does not play a significant role in the likelihood of customers discontinuing the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Converting merged dataset to csv\n",
    "df.to_csv('merged_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Drop the 'customerid', 'churn_encoded' and 'monthly_charges_bin' columns\n",
    "df = df.drop(['customerid', 'churn_encoded', 'monthly_charges_bin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check dataframe\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check for missing values in the churn column\n",
    "missing_values = df['churn'].isnull().sum()\n",
    "\n",
    "if missing_values == 0:\n",
    "    print(\"There are no missing values in the churn column.\")\n",
    "else:\n",
    "    print(f\"There is {missing_values} missing value in the churn column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Drop rows with missing values in the churn column\n",
    "df.dropna(subset=['churn'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check to confirm the missing values in the churn column\n",
    "missing_values = df['churn'].isnull().sum()\n",
    "\n",
    "if missing_values == 0:\n",
    "    print(\"There are no missing values in the churn column.\")\n",
    "else:\n",
    "    print(f\"There are {missing_values} missing values in the churn column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Change the data type of the seniorcitizen column to object\n",
    "df['seniorcitizen'] = df['seniorcitizen'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To check if the dataset is balanced, we set a threshold of 5%. If the absolute difference between the counts of the two classes is less than the threshold, then the dataset is considered balanced; otherwise, it's considered imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#The target variable is 'churn' and it binary are (Yes/No)\n",
    "#Count the occurrences of each class\n",
    "class_counts = df['churn'].value_counts()\n",
    "\n",
    "#Set the threshold for imbalance(5% of the total number of rows)\n",
    "threshold = len(df) * 0.05 \n",
    "\n",
    "#Check if the dataset is balanced\n",
    "is_balanced = abs(class_counts[0] - class_counts[1]) < threshold  \n",
    "\n",
    "if is_balanced:\n",
    "    print(\"The dataset is balanced.\")\n",
    "else:\n",
    "    print(\"The dataset is imbalanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Count the occurrences of each class\n",
    "class_counts = df['churn'].value_counts()\n",
    "\n",
    "#Plot the distribution of the target variable\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = class_counts.plot(kind='bar', color=['skyblue', 'orange'])\n",
    "plt.title('Distribution of Churn')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "#Annotate the bars with churn counts\n",
    "for i, count in enumerate(class_counts):\n",
    "    plt.text(i, count + 10, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The visual also confirms the dataset is not balanced since it has more 'No' values than 'Yes' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING THE IMBALANCED DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the Dataset into Training and Evaluation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In splitting the data, it is done such that;\n",
    "X contains all the features except the target variable (churn).\n",
    "\n",
    "y contains only the target variable (churn).\n",
    "\n",
    "We use train_test_split to split the data into training and evaluation sets and set test_size to 0.3 which specifies that 30% of the data should be used for evaluation, while the rest is used for training. \n",
    "\n",
    "X_train and y_train contain the training features and target variable respectively.X_eval and y_eval contain the evaluation features and target variable respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Define features (X) and target variable (y)\n",
    "X = df.drop('churn', axis=1) \n",
    "y = df['churn']  \n",
    "\n",
    "#Split the dataset into training and evaluation sets\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode the y train and evaluation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#Encode the target variable 'churn' for training set\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "#Encode the target variable 'churn' for evaluation set\n",
    "y_eval_encoded = label_encoder.transform(y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Identify the categorical columns\n",
    "X.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Identify the numerical columns\n",
    "X.select_dtypes('number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Define numerical and categorical features\n",
    "numerical_features = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "categorical_features = ['gender', 'seniorcitizen', 'partner', 'dependents', 'phoneservice',\n",
    "                        'multiplelines', 'internetservice', 'onlinesecurity', 'onlinebackup',\n",
    "                        'deviceprotection', 'techsupport', 'streamingtv', 'streamingmovies',\n",
    "                        'contract', 'paperlessbilling', 'paymentmethod']\n",
    "\n",
    "#Create preprocessing steps for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('num_imputer', SimpleImputer(strategy='median')),  #Fill missing values with the median\n",
    "    ('scaler', StandardScaler())  #Scale the numerical features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  #One-hot encode categorical features\n",
    "])\n",
    "\n",
    "#Combine preprocessing steps for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ \n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODELLING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Define the models\n",
    "models = [\n",
    "    ('K-Nearest_Neighbors', KNeighborsClassifier(n_neighbors=5)),  \n",
    "    ('Logistic_Regression', LogisticRegression(random_state=42)),  \n",
    "    ('Support_Vector_Machine', SVC(random_state=42)),  \n",
    "    ('Decision_Tree', DecisionTreeClassifier(random_state=42)),  \n",
    "    ('Random_Forest', RandomForestClassifier(random_state=42)),  \n",
    "    ('Gradient_Boosting', GradientBoostingClassifier(random_state=42)),  \n",
    "]\n",
    "\n",
    "#Creating dictionary for the models\n",
    "all_pipelines = {}\n",
    "\n",
    "#Create a DataFrame for the metrics\n",
    "metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "#Train and evaluate each model\n",
    "for model_name, classifier in models:\n",
    "    #Create a pipeline for the model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', classifier)])  \n",
    "    \n",
    "    #Train the model\n",
    "    pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "    #Add all pipeline to the all_pipeline dictionary\n",
    "    all_pipelines[model_name] = pipeline\n",
    "    \n",
    "    #Make predictions on the test set\n",
    "    y_pred = pipeline.predict(X_eval)\n",
    "\n",
    "    #Generate classification report for each model\n",
    "    metrics = classification_report(y_eval_encoded, y_pred, output_dict=True)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    accuracy = metrics['accuracy']\n",
    "    precision = metrics['weighted avg']['precision']\n",
    "    recall = metrics['weighted avg']['recall']\n",
    "    f1_score= metrics['weighted avg']['f1-score']\n",
    "\n",
    "    #Add metrics to metrics_output\n",
    "    metrics_output.loc[len(metrics_output)] = [model_name, accuracy, precision, recall, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Display the metrics_output\n",
    "metrics_output.sort_values(ascending=False, by='f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Support Vector Machine (SVM): It has the highest F1 score among all models, indicating a good balance between precision and recall. This means it's effective at both correctly identifying positive cases (precision) and capturing most of the positive cases in the dataset (recall).\n",
    "\n",
    "* Gradient Boosting: It also has a high F1 score, very close to SVM, indicating a similar balance between precision and recall. This suggests it's also effective at correctly classifying positive cases while capturing most of them.\n",
    "\n",
    "* Logistic Regression and Random Forest: They have slightly lower F1 scores compared to SVM and Gradient Boosting, but they still maintain a reasonable balance between precision and recall. They might not be as good as SVM and Gradient Boosting in capturing all positive cases, but they provide decent overall performance.\n",
    "\n",
    "* K-Nearest Neighbors (KNN): It has a lower F1 score compared to other models, indicating a weaker balance between precision and recall. This suggests it may struggle more with correctly identifying positive cases or capturing all of them.\n",
    "\n",
    "* Decision Tree: It has the lowest F1 score among all models, indicating the weakest balance between precision and recall. This suggests it might have trouble both correctly classifying positive cases and capturing all of them.\n",
    "\n",
    "In summary, based on F1 score, SVM and Gradient Boosting are the top-performing models, followed by Logistic Regression and Random Forest, while KNN and Decision Tree lag behind in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING THE BALANCED DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Creating dictionary for the models\n",
    "all_balanced_pipelines = {}\n",
    "\n",
    "# Create a DataFrame for the metrics\n",
    "balanced_metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, classifier in models:\n",
    "    # Create a pipeline for the model\n",
    "    balanced_pipeline = imbPipeline(steps=[('preprocessor', preprocessor),\n",
    "                                           ('smote-sampler', SMOTE(random_state=42)), \n",
    "                                           ('classifier', classifier)])  \n",
    "    \n",
    "    # Train the model\n",
    "    balanced_pipeline.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    # Add all pipeline to the all_pipeline dictionary\n",
    "    all_balanced_pipelines[model_name] = balanced_pipeline\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = balanced_pipeline.predict(X_eval)\n",
    "\n",
    "    # Generate classification report for each model\n",
    "    balanced_metrics = classification_report(y_eval_encoded, y_pred, output_dict=True)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = balanced_metrics['accuracy']\n",
    "    precision = balanced_metrics['weighted avg']['precision']\n",
    "    recall = balanced_metrics['weighted avg']['recall']\n",
    "    f1_score = balanced_metrics['weighted avg']['f1-score']\n",
    "\n",
    "    # Add metrics to metrics_output\n",
    "    balanced_metrics_output.loc[len(balanced_metrics_output)] = [model_name, accuracy, precision, recall, f1_score]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Display the metrics_output\n",
    "balanced_metrics_output.sort_values(ascending=False, by='f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is the reults of the performance of the models after balancing the dataset.\n",
    "* Random Forest achieved the highest accuracy and F1 score among the models, indicating that it performed well overall in terms of correctly classifying instances and achieving a balance between precision and recall. It also had relatively high precision and recall.\n",
    "\n",
    "* Gradient Boosting had slightly lower accuracy and F1 score compared to Random Forest but still performed well overall. It had similar precision and recall to Random Forest.\n",
    "\n",
    "* Support Vector Machine (SVM) had the highest precision among the models, suggesting that it had the fewest false positive predictions. However, its accuracy and F1 score were slightly lower than those of Random Forest and Gradient Boosting.\n",
    "\n",
    "* Logistic Regression had moderate performance, with accuracy, precision, recall, and F1 score falling in the mid-range among the models.\n",
    "\n",
    "* Decision Tree showed lower performance compared to Random Forest and Gradient Boosting, with lower accuracy, precision, recall, and F1 score.\n",
    "\n",
    "* K-Nearest Neighbors (KNN) had the lowest performance overall, with the lowest accuracy, precision, recall, and F1 score among the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying feature selection to improve performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Creating dictionary for the models\n",
    "all_bf_pipelines = {}\n",
    "\n",
    "# Create a DataFrame for the metrics\n",
    "bf_metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, classifier in models:\n",
    "    # Create a pipeline for the model\n",
    "    bf_pipeline = imbPipeline(steps=[('preprocessor', preprocessor),\n",
    "                                           ('smote-sampler', SMOTE(random_state=42)), \n",
    "                                           ('feature_selection', SelectKBest(mutual_info_classif, k='all')),\n",
    "                                           ('classifier', classifier)])\n",
    "    \n",
    "    # Train the model\n",
    "    bf_pipeline.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    # Add all pipeline to the all_pipeline dictionary\n",
    "    all_bf_pipelines[model_name] = bf_pipeline\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = bf_pipeline.predict(X_eval)\n",
    "\n",
    "    # Generate classification report for each model\n",
    "    bf_metrics = classification_report(y_eval_encoded, y_pred, output_dict=True)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = bf_metrics['accuracy']\n",
    "    precision = bf_metrics['weighted avg']['precision']\n",
    "    recall = bf_metrics['weighted avg']['recall']\n",
    "    f1_score = bf_metrics['weighted avg']['f1-score']\n",
    "\n",
    "    # Add metrics to metrics_output\n",
    "    bf_metrics_output.loc[len(bf_metrics_output)] = [model_name, accuracy, precision, recall, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Display the metrics_output\n",
    "bf_metrics_output.sort_values(ascending=False, by='f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The performance of the models are still not the best so we will consider more methods that can improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding confusion matrix to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Creating dictionary for the models\n",
    "all_bf_pipelines = {}\n",
    "\n",
    "# Create confusion matrix dictionary\n",
    "all_confusion_matrix = {}\n",
    "\n",
    "# Create a DataFrame for the metrics\n",
    "bf_metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, classifier in models:\n",
    "    # Create a pipeline for the model\n",
    "    bf_pipeline = imbPipeline(steps=[('preprocessor', preprocessor),\n",
    "                                           ('smote-sampler', SMOTE(random_state=42)), \n",
    "                                           ('feature_selection', SelectKBest(mutual_info_classif, k='all')),\n",
    "                                           ('classifier', classifier)])\n",
    "    \n",
    "    # Train the model\n",
    "    bf_pipeline.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    # Add all pipeline to the all_pipeline dictionary\n",
    "    all_bf_pipelines[model_name] = bf_pipeline\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = bf_pipeline.predict(X_eval)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_eval_encoded, y_pred)\n",
    "\n",
    "    # Add confusion matrix to the dictionary\n",
    "    all_confusion_matrix[model_name] = conf_matrix\n",
    "\n",
    "    # Generate classification report for each model\n",
    "    bf_metrics = classification_report(y_eval_encoded, y_pred, output_dict=True)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = bf_metrics['accuracy']\n",
    "    precision = bf_metrics['weighted avg']['precision']\n",
    "    recall = bf_metrics['weighted avg']['recall']\n",
    "    f1_score = bf_metrics['weighted avg']['f1-score']\n",
    "\n",
    "    # Add metrics to metrics_output\n",
    "    bf_metrics_output.loc[len(bf_metrics_output)] = [model_name, accuracy, precision, recall, f1_score]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Iterate over the keys (model names) in the all_confusion_matrix dictionary\n",
    "for model_name, confusion_matrix in all_confusion_matrix.items():\n",
    "    print(f\"Confusion Matrix for {model_name}:\")\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### These confusion matrices provide information about the performance of each model. They show how many instances were correctly or incorrectly classified by the model. For example, in the case of K-Nearest Neighbors, out of 1497 instances:\n",
    "* 297 were correctly classified as positive (churn).\n",
    "\n",
    "* 736 were correctly classified as negative (not churn).\n",
    "\n",
    "* 376 were incorrectly classified as positive (predicted as churn but actually not churn).\n",
    "\n",
    "* 104 were incorrectly classified as negative (predicted as not churn but actually churn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define model names and confusion matrices\n",
    "models = ['K-Nearest_Neighbors', 'Logistic_Regression', 'Support_Vector_Machine', 'Decision_Tree', 'Random_Forest', 'Gradient_Boosting']\n",
    "confusion_matrices = [\n",
    "    [[736, 376], [104, 297]],\n",
    "    [[800, 312], [85, 316]],\n",
    "    [[858, 254], [112, 289]],\n",
    "    [[857, 255], [181, 220]],\n",
    "    [[947, 165], [182, 219]],\n",
    "    [[905, 207], [146, 255]]\n",
    "]\n",
    "\n",
    "# Plot confusion matrices using heatmaps\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, (model, cm) in enumerate(zip(models, confusion_matrices)):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_title(f\"Confusion Matrix for {model}\")\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Considering both the false positive rate (FPR) and the false negative rate (FNR) for each model;\n",
    "* Logistic Regression and Support Vector Machine (SVM) have relatively lower false positive rates and false negative rates compared to other models, indicating better overall performance in terms of minimizing classification errors.\n",
    "\n",
    "* K-Nearest Neighbors (KNN) also has a relatively low false negative rate but a higher false positive rate compared to Logistic Regression and SVM.\n",
    "\n",
    "* Decision Tree, Random Forest, and Gradient Boosting have higher false negative rates, indicating a higher tendency to miss positive cases.\n",
    "\n",
    "* Therefore, Logistic Regression and Support Vector Machine (SVM) appear to be the best models with fewer false positives and false negatives in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for the sensitivity and specificity Threshold of the models\n",
    "\n",
    "* The goal here is to improve the False Positives and the the False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define model names and confusion matrices\n",
    "models = ['K-Nearest_Neighbors', 'Logistic_Regression', 'Support_Vector_Machine', 'Decision_Tree', 'Random_Forest', 'Gradient_Boosting']\n",
    "confusion_matrices = [\n",
    "    [[736, 376], [104, 297]],\n",
    "    [[800, 312], [85, 316]],\n",
    "    [[858, 254], [112, 289]],\n",
    "    [[857, 255], [181, 220]],\n",
    "    [[947, 165], [182, 219]],\n",
    "    [[905, 207], [146, 255]]\n",
    "]\n",
    "\n",
    "# Iterate over models and confusion matrices\n",
    "for model_name, conf_matrix in zip(models, confusion_matrices):\n",
    "    # Correcting False Negatives\n",
    "    true_positives = conf_matrix[1][1]\n",
    "    false_negatives = conf_matrix[1][0]\n",
    "    total_positives = true_positives + false_negatives\n",
    "\n",
    "    # Adjusting sensitivity (recall) threshold to correct false negatives\n",
    "    sensitivity_threshold = true_positives / total_positives\n",
    "    print(f\"{model_name}: Sensitivity Threshold = {sensitivity_threshold}\")\n",
    "\n",
    "    # Correcting False Positives\n",
    "    true_negatives = conf_matrix[0][0]\n",
    "    false_positives = conf_matrix[0][1]\n",
    "    total_negatives = true_negatives + false_positives\n",
    "\n",
    "    # Adjusting specificity (precision) threshold to correct false positives\n",
    "    specificity_threshold = true_negatives / total_negatives\n",
    "    print(f\"{model_name}: Specificity Threshold = {specificity_threshold}\")\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define sensitivity and specificity thresholds for each model\n",
    "thresholds = {\n",
    "    'K-Nearest_Neighbors': {'sensitivity': 0.7406483790523691, 'specificity': 0.6618705035971223},\n",
    "    'Logistic_Regression': {'sensitivity': 0.7880299251870324, 'specificity': 0.7194244604316546},\n",
    "    'Support_Vector_Machine': {'sensitivity': 0.7206982543640897, 'specificity': 0.7715827338129496},\n",
    "    'Decision_Tree': {'sensitivity': 0.5486284289276808, 'specificity': 0.77068345323741},\n",
    "    'Random_Forest': {'sensitivity': 0.5461346633416458, 'specificity': 0.8516187050359713},\n",
    "    'Gradient_Boosting': {'sensitivity': 0.6359102244389028, 'specificity': 0.8138489208633094}\n",
    "}\n",
    "\n",
    "# Iterate over the models and adjust thresholds\n",
    "adjusted_models = {}\n",
    "for model_name, pipeline in all_bf_pipelines.items():\n",
    "    sensitivity_threshold = thresholds[model_name]['sensitivity']\n",
    "    specificity_threshold = thresholds[model_name]['specificity']\n",
    "\n",
    "    # Create a pipeline for the Support Vector Machine model with probability=True\n",
    "    if model_name == 'Support_Vector_Machine':\n",
    "        pipeline.steps[-1] = ('classifier', SVC(probability=True))\n",
    "        pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Get predicted probabilities for positive class (churn)\n",
    "    y_pred_prob = pipeline.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "    # Adjust decision threshold based on sensitivity and specificity thresholds\n",
    "    adjusted_y_pred = (y_pred_prob >= sensitivity_threshold).astype(int)\n",
    "\n",
    "    # Apply specificity threshold\n",
    "    adjusted_y_pred[(y_pred_prob >= specificity_threshold) & (adjusted_y_pred == 0)] = 0\n",
    "\n",
    "    # Store adjusted predictions in dictionary\n",
    "    adjusted_models[model_name] = adjusted_y_pred\n",
    "\n",
    "# Evaluate adjusted models\n",
    "adjusted_metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f_score'])\n",
    "for model_name, adjusted_y_pred in adjusted_models.items():\n",
    "    # Calculate metrics using adjusted predictions\n",
    "    accuracy = accuracy_score(y_eval_encoded, adjusted_y_pred)\n",
    "    precision = precision_score(y_eval_encoded, adjusted_y_pred)\n",
    "    recall = recall_score(y_eval_encoded, adjusted_y_pred)\n",
    "    f_score = f1_score(y_eval_encoded, adjusted_y_pred)\n",
    "\n",
    "    # Add metrics to adjusted_metrics_output\n",
    "    adjusted_metrics_output.loc[len(adjusted_metrics_output)] = [model_name, accuracy, precision, recall, f_score]\n",
    "\n",
    "# Display adjusted metrics\n",
    "print(adjusted_metrics_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define sensitivity and specificity thresholds for each model\n",
    "thresholds = {\n",
    "    'K-Nearest_Neighbors': {'sensitivity': 0.7406483790523691, 'specificity': 0.6618705035971223},\n",
    "    'Logistic_Regression': {'sensitivity': 0.7880299251870324, 'specificity': 0.7194244604316546},\n",
    "    'Support_Vector_Machine': {'sensitivity': 0.7206982543640897, 'specificity': 0.7715827338129496},\n",
    "    'Decision_Tree': {'sensitivity': 0.5486284289276808, 'specificity': 0.77068345323741},\n",
    "    'Random_Forest': {'sensitivity': 0.5461346633416458, 'specificity': 0.8516187050359713},\n",
    "    'Gradient_Boosting': {'sensitivity': 0.6359102244389028, 'specificity': 0.8138489208633094}\n",
    "}\n",
    "\n",
    "# Iterate over the models and adjust thresholds\n",
    "adjusted_models = {}\n",
    "for model_name, pipeline in all_bf_pipelines.items():\n",
    "    sensitivity_threshold = thresholds[model_name]['sensitivity']\n",
    "    specificity_threshold = thresholds[model_name]['specificity']\n",
    "\n",
    "    # Create a pipeline for the Support Vector Machine model with probability=True\n",
    "    if model_name == 'Support_Vector_Machine':\n",
    "        pipeline.steps[-1] = ('classifier', SVC(probability=True))\n",
    "        pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Get predicted probabilities for positive class (churn)\n",
    "    y_pred_prob = pipeline.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "    # Adjust decision threshold based on sensitivity and specificity thresholds\n",
    "    adjusted_y_pred = (y_pred_prob >= sensitivity_threshold).astype(int)\n",
    "\n",
    "    # Apply specificity threshold\n",
    "    adjusted_y_pred[(y_pred_prob >= specificity_threshold) & (adjusted_y_pred == 0)] = 0\n",
    "\n",
    "    # Store adjusted predictions in dictionary\n",
    "    adjusted_models[model_name] = adjusted_y_pred\n",
    "\n",
    "# Evaluate adjusted models\n",
    "adjusted_metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f1_score'])\n",
    "for model_name, adjusted_y_pred in adjusted_models.items():\n",
    "    # Calculate metrics using adjusted predictions\n",
    "    accuracy = accuracy_score(y_eval_encoded, adjusted_y_pred)\n",
    "    precision = precision_score(y_eval_encoded, adjusted_y_pred)\n",
    "    recall = recall_score(y_eval_encoded, adjusted_y_pred)\n",
    "    f1 = f1_score(y_eval_encoded, adjusted_y_pred)  # Corrected variable name\n",
    "\n",
    "    # Add metrics to adjusted_metrics_output\n",
    "    adjusted_metrics_output.loc[len(adjusted_metrics_output)] = [model_name, accuracy, precision, recall, f1]\n",
    "\n",
    "# Display adjusted metrics\n",
    "print(adjusted_metrics_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
