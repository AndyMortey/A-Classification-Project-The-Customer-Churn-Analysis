{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A CLASSIFICATION PROJECT - CUSTOMER CHURN ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROJECT SCENARIO\n",
    "As a data scientist at Vodafone Corporation, a large telecommunication company.\n",
    "* Vodafone want to find the likelihood of a customer leaving the organization, the key indicators of churn as well as the retention strategies that can be implemented to avert this problem.\n",
    "* To do this, the business development unit has provided you with data to build a series of machine learning models to predict customer churn.\n",
    "* The marketing and sales team as well have provided you with some data to aid this endeavor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROJECT DESCRIPTION\n",
    " Telecommunication companies face the ongoing challenge of customer churn, where subscribers discontinue services and switch to competitors. \n",
    " To address this issue and proactively retain customers, we are undertaking a customer churn analysis project utilizing machine learning techniques. \n",
    " In this project, we explore how machine learning techniques can be leveraged for customer churn analysis in telecommunication networks, following the well-established CRISP-DM (Cross-Industry Standard Process for Data Mining) framework. The primary objective of this project is to develop predictive models that can accurately identify customers at risk of churn in our telecommunication network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUSINESS UNDERSTANDING\n",
    "In today's highly competitive telecommunication industry, customer churn, or the loss of customers to competitors, poses a significant challenge for companies striving to maintain market share and profitability. \n",
    "Identifying customers at risk of churn and implementing proactive retention strategies is crucial for sustaining business growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HYPOTHESIS\n",
    "NULL HYPOTHESIS: There is no relationship between the tenure and the churn of customers.\n",
    "\n",
    "ALTERNATE HYPOTHESIS: There is a relationship between the tenure and the churn of customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANALYTICAL QUESTIONS\n",
    "1. What is the overall churn rate of the telecommunication company?\n",
    "2. Does churn rate differ based on the payment method?\n",
    "3. What is the churn rate of customers based on their seniority?\n",
    "4. What is the churn rate of customers based on their monthlycharges?\n",
    "5. What is the churn rate of customers based on their contract type?\n",
    "6. What is the churn rate of customers based on their gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyodbc\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import dotenv_values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "#Machine Learning Packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Loading first dataset from database\n",
    "# Load environment variables from .env file\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Access database credentials from environment variables dictionary\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "password = environment_variables.get(\"PASSWORD\")\n",
    "username = environment_variables.get(\"USERNAME\")\n",
    "\n",
    "# Construct the connection string\n",
    "connection_string = f\"DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};User Id={username};PASSWORD={password};\"\n",
    "\n",
    "print(\"USERNAME:\", username)\n",
    "\n",
    "# Construct the connection string\n",
    "connection_string = f\"DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};UID={username};PWD={password};\"\n",
    "# Connect to the database\n",
    "try:\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# Specify the SQL queries to extract data from the tables\n",
    "Dataset1 = \"SELECT * FROM dbo.LP2_Telco_churn_first_3000\"\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a cursor from the connection\n",
    "with connection.cursor() as cursor:\n",
    "    # Execute the queries and fetch data into Pandas DataFrames\n",
    "    Dataset1 = pd.read_sql_query(Dataset1, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Preview the first dataset\n",
    "Dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Load the second the dataset\n",
    "Dataset2 = pd.read_csv(\"./Dataset/LP2_Telco-churn-second-2000.csv\")\n",
    "Dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the columns\n",
    "column_names = Dataset1.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the columns\n",
    "column_names = Dataset2.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the number of rows and columns\n",
    "Dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the number of rows and columns\n",
    "Dataset2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. The outputs show both datasets have the same column names and number of columns so they can be merged easily.\n",
    "2. However, some of the column names are in upper case so they will be converted to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert column names to lower case\n",
    "Dataset1.columns = Dataset1.columns.str.lower()\n",
    "\n",
    "#Check the columns to confirm\n",
    "column_names = Dataset1.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert column names to lower case\n",
    "Dataset2.columns = Dataset2.columns.str.lower()\n",
    "\n",
    "#Check the columns to confirm\n",
    "column_names = Dataset2.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check cell values\n",
    "Dataset1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows there are empty cells in these columns; multiplelines, onlinesecurity, onlinebackup, deviceprotection, techsupport, streamingtv, streamingmovies, totalcharges and churn. They will be treated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check cell values\n",
    "Dataset2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows there are no empty cells in any of the columns but some of the columns have the wrong datatype. This will be taken care of accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check for the unique values of each column\n",
    "def check_unique_values(df):\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "\n",
    "#Check for Dataset1\n",
    "check_unique_values(Dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def check_unique_values(df):\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "\n",
    "#Check for Dataset2\n",
    "check_unique_values(Dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 'True' and 'False' values in the first dataset will be replaced with 'Yes' and 'No' to ensure both datasets have the same values before they are merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Replace the \"True\" and \"False\" values in Dataset1\n",
    "def replace_true_false(df):\n",
    "    df.replace({True: 'Yes', False: 'No'}, inplace=True)\n",
    "\n",
    "replace_true_false(Dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check Dataset1 to confirm\n",
    "Dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Replace the values in seniorcitizen column\n",
    "def replace_yes_no_with_1_0(df):\n",
    "    df['seniorcitizen'] = df['seniorcitizen'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "replace_yes_no_with_1_0(Dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check Dataset1 to confirm\n",
    "Dataset1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since the columns and values for both datasets are similar now, we will merge both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Merge both datasets\n",
    "df = pd.concat([Dataset1, Dataset2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check merged dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check cell values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 'totalcharges' column has the wrong datatype. It will be converted into a float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert 'totalcharges' column to numeric (float)\n",
    "df['totalcharges'] = pd.to_numeric(df['totalcharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check cell values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def check_unique_values(df):\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "\n",
    "#Check for Dataset2\n",
    "check_unique_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "#List of categorical columns\n",
    "categorical_columns = ['gender', 'partner', 'dependents', 'phoneservice', 'multiplelines', \n",
    "                       'internetservice', 'onlinesecurity', 'onlinebackup', 'deviceprotection', \n",
    "                       'techsupport', 'streamingtv', 'streamingmovies', 'contract', \n",
    "                       'paperlessbilling', 'paymentmethod', 'churn']\n",
    "\n",
    "#Set up the figure and axes for plotting\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(18, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "#Loop through each categorical column and plot the frequency of each category\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    #Check for duplicate labels and drop them\n",
    "    unique_values = df[column].unique()\n",
    "    if len(unique_values) != df[column].nunique():\n",
    "        df_unique = df.drop_duplicates(subset=column)\n",
    "        sns.countplot(x=column, data=df_unique, ax=axes[i])\n",
    "    else:\n",
    "        sns.countplot(x=column, data=df, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "#Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#List of numerical columns\n",
    "numerical_columns = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "\n",
    "#Set up the figure and axes for plotting\n",
    "fig, axes = plt.subplots(nrows=len(numerical_columns), ncols=1, figsize=(8, 5*len(numerical_columns)))\n",
    "\n",
    "#Loop through each numerical column and plot its histogram\n",
    "for i, column in enumerate(numerical_columns):\n",
    "    df[column].hist(ax=axes[i], bins=20, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "#Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Boolean variable to analyze\n",
    "boolean_variable = 'seniorcitizen'\n",
    "\n",
    "#Calculate the proportion of 'True' and 'False' values\n",
    "proportion_true = df[boolean_variable].sum() / len(df)\n",
    "proportion_false = 1 - proportion_true\n",
    "\n",
    "#Plot the proportions\n",
    "sns.barplot(x=['True', 'False'], y=[proportion_true, proportion_false])\n",
    "plt.title(f'Proportion of True and False values in {boolean_variable}')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check summary statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "1. The 'seniorcitizen', 'tenure' and 'monthlycharges' columns do not have any missing values but the 'totalcharges' column has missing values.\n",
    "2. The average monthlycharge is approximately 65.09, the minimum monthlycharge is approximately 18.4 and the maximum monthlycharge is approximately 118.65. \n",
    "3. In the 'tenure' column, the standard deviation is approximately 24.53, indicating that the values are spread out over a wide range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check 'tenure' \n",
    "numerical_column = ['tenure']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[numerical_column])\n",
    "plt.title('Box Plot of Tenure')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check 'monthlycharges' \n",
    "numerical_column = ['monthlycharges']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[numerical_column])\n",
    "plt.title('Box Plot of MonthlyCharges')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check 'totalcharges' \n",
    "numerical_column = ['totalcharges']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[numerical_column])\n",
    "plt.title('Box Plot of TotalCharges')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "1. This shows all the columns do not have any outliers.\n",
    "2. The 'tenure' boxplot suggests a fairly even distribution of tenure values across the dataset.\n",
    "3. The 'monthlycharges' boxplot suggests that most customers have monthly charges clustered around the median, with a fairly consistent spread across the quartiles.\n",
    "4. The 'totalcharges' values are concentrated between approximately 2000 and 4000, with the median closer to Q3, suggesting a skew towards higher charges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gender Vrs Churn Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Get the count of churn for each gender\n",
    "gender_churn_counts = df.groupby(['gender', 'churn']).size().unstack(fill_value=0)\n",
    "\n",
    "print(gender_churn_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Plot Gender vs. Churn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='gender', hue='churn', data=df)\n",
    "plt.title('Gender vs. Churn')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Churn', labels=['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This implies that among females, 1823 customers did not churn, and 661 customers did churn. Similarly, among males, 1883 customers did not churn, and 675 customers did churn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Select the relevant columns\n",
    "selected_columns = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "selected_corr_matrix = df[selected_columns].corr()\n",
    "\n",
    "#Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(selected_corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Heatmap of Numerical Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. Tenure vs. Monthly Charges: Thereâ€™s a weak positive correlation of (0.24), suggesting that as tenure increases, monthly charges tend to increase slightly.\n",
    "2. Tenure vs. Total Charges: A strong positive correlation of (0.83) is observed here, indicating that longer tenure is strongly associated with higher total charges.\n",
    "3. Monthly Charges vs. Total Charges: This pair shows a moderate positive correlation of (0.65), meaning as monthly charges increase, total charges also tend to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contract Vrs Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "contract_churn_counts = df.groupby(['contract', 'churn']).size()\n",
    "print(contract_churn_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='contract', hue='churn', data=df)\n",
    "plt.title('Contract vs. Churn')\n",
    "plt.xlabel('Contract')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Churn', loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. For customers with a 'Month-to-month' contract, there are 1560 customers who did not churn (No) and 1184 customers who did churn (Yes).\n",
    "2. For customers with a 'One year' contract, there are 933 customers who did not churn and 122 customers who did churn.\n",
    "3. For customers with a 'Two year' contract, there are 1213 customers who did not churn and 30 customers who did churn.\n",
    "4. It can be concluded that customers with shorter-term contracts (like 'Month-to-month') tend to churn more compared to those with longer-term contracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 'churn' column contains string values ('Yes' and 'No'), which cannot be converted to float for correlation calculation. To perform correlation analysis, we need to encode these categorical values into numerical values first. One common approach is to use label encoding, where 'Yes' is replaced with 1 and 'No' is replaced with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#Encode the 'churn' column\n",
    "df['churn_encoded'] = label_encoder.fit_transform(df['churn'])\n",
    "\n",
    "#Calculate correlation matrix\n",
    "correlation_matrix = df[['tenure', 'monthlycharges', 'totalcharges', 'churn_encoded']].corr()\n",
    "\n",
    "#Display correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "1. tenure vs. monthlycharges: There is a positive correlation of approximately 0.24, indicating that as tenure increases, monthly charges also tend to increase, but the correlation is not very strong.\n",
    "2. tenure vs. totalcharges: There is a strong positive correlation of approximately 0.83, suggesting that as tenure increases, total charges also increase.\n",
    "3. tenure vs. churn_encoded: There is a negative correlation of approximately -0.35, indicating that as tenure increases, the likelihood of churn decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPOTHESIS TESTING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null Hypothesis: There is no relationship between the tenure and the churn of customers.\n",
    "Alternate Hypothesis: There is a relationship between the tenure and the churn of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Create a contingency table\n",
    "contingency_table = pd.crosstab(df['tenure'], df['churn'])\n",
    "\n",
    "#Perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "#Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"P-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "\n",
    "#Compare p-value with alpha to make a decision\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a relationship between tenure and churn.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no relationship between tenure and churn.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on the p-value (which is far below the significance level of 0.05), we reject the null hypothesis. This means that there is sufficient evidence to conclude that there is a statistically significant relationship between tenure and churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWERING THE ANALYTICAL QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the overall churn rate against retained customers?\n",
    "2. Does churn rate differ based on the payment method?\n",
    "3. What is the churn rate of customers based on their seniority?\n",
    "4. What is the churn rate of customers based on their monthlycharges?\n",
    "5. What is the churn rate of customers based on their contract type?\n",
    "6. What is the churn rate of customers based on their gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question One: What is the overall churn rate against retained customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Count the number of customers who churned\n",
    "churned_count = df['churn'].value_counts()['Yes']\n",
    "\n",
    "#Calculate the total number of customers\n",
    "total_customers = len(df)\n",
    "\n",
    "#Calculate the overall churn rate\n",
    "overall_churn_rate = (churned_count / total_customers) * 100\n",
    "\n",
    "print(\"Overall churn rate:\", overall_churn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Calculate the churn rates as percentages\n",
    "churn_rate_percentage = (churned_count / total_customers) * 100\n",
    "retention_rate_percentage = 100 - churn_rate_percentage\n",
    "\n",
    "#Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar([\"Churned\", \"Retained\"], [churn_rate_percentage, retention_rate_percentage], color=['orange', 'skyblue'])\n",
    "plt.title(\"Overall Churn Rate\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "#Show the percentages on the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, f\"{yval:.2f}%\", va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows a bar plot with two bars: one for the churned customers and one for the retained customers. It shows there are more retained customers than customers that churned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Two: Does churn rate differ based on the payment method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Calculate churn rate for each payment method\n",
    "payment_churn_rates = df.groupby('paymentmethod')['churn'].value_counts(normalize=True).loc[:, 'Yes'] * 100\n",
    "\n",
    "# Plot churn rate based on payment method\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = payment_churn_rates.plot(kind='bar', color='skyblue')\n",
    "plt.title('Churn Rate by Payment Method')\n",
    "plt.xlabel('Payment Method')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "#Add labels on top of each bar\n",
    "for i, rate in enumerate(payment_churn_rates):\n",
    "    plt.text(i, rate, f'{rate:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows that customers using electronic check have the highest churn rate, which could suggest issues with this payment method. This might be as a result of user dissatisfaction hence requires further investigation and improvement of the payment process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Three: What is the churn rate of customers based on their Seniority?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculate churn rate based on seniority\n",
    "seniority_churn_rate = df.groupby('seniorcitizen')['churn'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
    "\n",
    "# Plot churn rate based on seniority using a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(seniority_churn_rate, labels=['Senior Citizen' if seniority == 1 else 'Non-Senior Citizen' for seniority in seniority_churn_rate.index], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Churn Rate by Seniority')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Four: What is the churn rate of customers based on their monthlycharges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check unique values in the monthlycharges column\n",
    "unique_monthlycharges = df['monthlycharges'].unique()\n",
    "\n",
    "#Print unique values\n",
    "print(unique_monthlycharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Define bins for monthly charges\n",
    "bins = [0, 30, 60, 90, 120]\n",
    "\n",
    "#Create labels for the bins\n",
    "labels = ['0-30', '30-60', '60-90', '90-120']\n",
    "\n",
    "#Assign each monthly charge to a bin\n",
    "df['monthly_charges_bin'] = pd.cut(df['monthlycharges'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "#Calculate churn rate based on monthly charges\n",
    "monthly_charges_churn_rate = df.groupby('monthly_charges_bin')['churn'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
    "\n",
    "#Plot churn rate based on monthly charges using a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = monthly_charges_churn_rate.plot(kind='bar', color='skyblue')\n",
    "plt.title('Churn Rate by Monthly Charges')\n",
    "plt.xlabel('Monthly Charges')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add labels on the bars\n",
    "for bar in bars.patches:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.5, f'{bar.get_height():.2f}%', ha='center', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This illustrates the relationship between the amount customers are charged monthly and the rate at which they stop using the service (churn rate). \n",
    "0-30 Range: Represents the lowest monthly charges and corresponds to the lowest churn rate, suggesting customers are satisfied with the service or find it affordable.\n",
    "\n",
    "30-60 Range: Shows a significant increase in churn rate, indicating a threshold where customers may begin to consider the service too expensive or not worth the cost.\n",
    "\n",
    "60-90 & 90-120 Ranges: Both have the highest and constant churn rates, suggesting that beyond a certain price point, the churn rate stabilizes, possibly due to a segment of customers who are less price-sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Five: What is the churn rate of customers based on their contract type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Calculate churn rate based on contract type\n",
    "contract_churn_rate = df.groupby('contract')['churn'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
    "\n",
    "#Plot churn rate based on contract type using a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = contract_churn_rate.plot(kind='bar', color='skyblue')\n",
    "plt.title('Churn Rate by Contract Type')\n",
    "plt.xlabel('Contract Type')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "#Add labels on the bars\n",
    "for bar in bars.patches:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.5, f'{bar.get_height():.2f}%', ha='center', color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This compares the churn rates across different contract durations. \n",
    "Month-to-Month: This category has the highest churn rate, around 40%, indicating that customers with no long-term commitments are more likely to discontinue the service.\n",
    "\n",
    "One Year: Shows a significantly lower churn rate of about 12%, suggesting increased customer retention with longer contract terms.\n",
    "\n",
    "Two Years: Has the lowest churn rate, which implies that the longest commitment contracts result in the best customer retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Six: What is the churn rate of customers based on their gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Calculate churn rate based on gender\n",
    "gender_churn_rate = df.groupby('gender')['churn'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
    "\n",
    "#Plot churn rate based on gender using a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = gender_churn_rate.plot(kind='bar', color='skyblue')\n",
    "plt.title('Churn Rate by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "#Add labels on the bars\n",
    "for bar in bars.patches:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.5, f'{bar.get_height():.2f}%', ha='center', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The churn rates are nearly identical for both genders, suggesting that gender does not play a significant role in the likelihood of customers discontinuing the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Converting merged dataset to csv\n",
    "df.to_csv('merged_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Drop the 'customerid', 'churn_encoded' and 'monthly_charges_bin' columns\n",
    "df = df.drop(['customerid', 'churn_encoded', 'monthly_charges_bin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check for missing values in the churn column\n",
    "missing_values = df['churn'].isnull().sum()\n",
    "\n",
    "if missing_values == 0:\n",
    "    print(\"There are no missing values in the churn column.\")\n",
    "else:\n",
    "    print(f\"There is {missing_values} missing value in the churn column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Drop rows with missing values in the churn column\n",
    "df.dropna(subset=['churn'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check to confirm the missing values in the churn column\n",
    "missing_values = df['churn'].isnull().sum()\n",
    "\n",
    "if missing_values == 0:\n",
    "    print(\"There are no missing values in the churn column.\")\n",
    "else:\n",
    "    print(f\"There are {missing_values} missing values in the churn column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Change the data type of the seniorcitizen column to object\n",
    "df['seniorcitizen'] = df['seniorcitizen'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To check if the dataset is balanced, we set a threshold of 5%. If the absolute difference between the counts of the two classes is less than the threshold, then the dataset is considered balanced; otherwise, it's considered imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#The target variable is 'churn' and it binary are (Yes/No)\n",
    "#Count the occurrences of each class\n",
    "class_counts = df['churn'].value_counts()\n",
    "\n",
    "#Set the threshold for imbalance(5% of the total number of rows)\n",
    "threshold = len(df) * 0.05 \n",
    "\n",
    "#Check if the dataset is balanced\n",
    "is_balanced = abs(class_counts[0] - class_counts[1]) < threshold  \n",
    "\n",
    "if is_balanced:\n",
    "    print(\"The dataset is balanced.\")\n",
    "else:\n",
    "    print(\"The dataset is imbalanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Count the occurrences of each class\n",
    "class_counts = df['churn'].value_counts()\n",
    "\n",
    "#Plot the distribution of the target variable\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = class_counts.plot(kind='bar', color=['skyblue', 'orange'])\n",
    "plt.title('Distribution of Churn')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "#Annotate the bars with churn counts\n",
    "for i, count in enumerate(class_counts):\n",
    "    plt.text(i, count + 10, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The visual also confirms the dataset is not balanced since it has more 'No' values than 'Yes' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check Dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the totalcharges column\n",
    "df[df['totalcharges']== '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "empty_totalcharges = df[df['totalcharges'].isna()]\n",
    "empty_totalcharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Replace the NaN values with 0\n",
    "df['totalcharges'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "empty_totalcharges = df[df['totalcharges'].isna()]\n",
    "empty_totalcharges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING THE IMBALANCED DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the Dataset into Training and Evaluation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In splitting the data, it is done such that;\n",
    "X contains all the features except the target variable (churn).\n",
    "\n",
    "y contains only the target variable (churn).\n",
    "\n",
    "We use train_test_split to split the data into training and evaluation sets and set test_size to 0.3 which specifies that 30% of the data should be used for evaluation, while the rest is used for training. \n",
    "\n",
    "X_train and y_train contain the training features and target variable respectively.X_eval and y_eval contain the evaluation features and target variable respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Define features (X) and target variable (y)\n",
    "X = df.drop('churn', axis=1) \n",
    "y = df['churn']  \n",
    "\n",
    "#Split the dataset into training and evaluation sets\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Instantiate encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#Encode y_train\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "\n",
    "#Encode y_test\n",
    "y_eval_encoded = encoder.transform(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Get categorical columns\n",
    "categorical_columns = X.select_dtypes('object').columns\n",
    "\n",
    "#Get numerical columns\n",
    "numerical_columns = X.select_dtypes('number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Prepare numerical pipeline\n",
    "numerical_pipeline=Pipeline(steps=[\n",
    "('numerical_imputer',SimpleImputer(strategy='median')),\n",
    "('scaler', StandardScaler())\n",
    "    \n",
    "])\n",
    "\n",
    "#Prepare categorical pipeline\n",
    "categorical_pipeline=Pipeline(steps=[\n",
    "    ('categorical_imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "\n",
    "])\n",
    "\n",
    "#Column transformer preparation\n",
    "preprocessor=ColumnTransformer(transformers=[\n",
    "    ('numerical_pipeline', numerical_pipeline,numerical_columns),\n",
    "    ('categorical_pipeline', categorical_pipeline, categorical_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODELLING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Define the models\n",
    "model = [\n",
    "    ('K-Nearest_Neighbors', KNeighborsClassifier(n_neighbors=5)),  \n",
    "    ('Logistic_Regression', LogisticRegression(random_state=42)),  \n",
    "    ('Support_Vector_Machine', SVC(random_state=42)),  \n",
    "    ('Decision_Tree', DecisionTreeClassifier(random_state=42)),  \n",
    "    ('Random_Forest', RandomForestClassifier(random_state=42)),  \n",
    "    ('Gradient_Boosting', GradientBoostingClassifier(random_state=42)),  \n",
    "]\n",
    "\n",
    "all_pipelines = {}\n",
    "\n",
    "#Create a DataFrame for the metrics\n",
    "metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "#Train and evaluate each model\n",
    "for model_name, classifier in model:\n",
    "    \n",
    "    #Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier),\n",
    "    ])\n",
    "    \n",
    "    #Fit data to pipeline\n",
    "    pipeline.fit(X_train, y_train_encoded)\n",
    "    all_pipelines[model_name] = pipeline\n",
    "\n",
    "    #Make predictions on the test set\n",
    "    y_pred = pipeline.predict(X_eval)\n",
    "\n",
    "    #Generate classification report for each model\n",
    "    metrics = classification_report(y_eval_encoded, y_pred, output_dict=True)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    accuracy = metrics['accuracy']\n",
    "    precision = metrics['weighted avg']['precision']\n",
    "    recall = metrics['weighted avg']['recall']\n",
    "    f1_score= metrics['weighted avg']['f1-score']\n",
    "\n",
    "    #Add metrics to metrics_output\n",
    "    metrics_output.loc[len(metrics_output)] = [model_name, accuracy, precision, recall, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Display the metrics_output\n",
    "metrics_output.sort_values(ascending=False, by='f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression and Gradient Boosting have the highest accuracy, precision, recall, and F1 score among the models listed.\n",
    "\n",
    "* Support Vector Machine (SVM) has lower precision compared to other models, indicating a higher number of false positives.\n",
    "\n",
    "* K-Nearest Neighbors performs reasonably well, with accuracy, precision, recall, and F1 score in the mid-range among the models evaluated. It's not the top-performing model in terms of accuracy, but its precision, recall, and F1 score are competitive with other models like Decision Tree and Random Forest.\n",
    "\n",
    "* Decision Tree and Random Forest have slightly lower accuracy compared to Logistic Regression and Gradient Boosting, but their precision, recall, and F1 score are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BALANCING THE UNBALANCED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Define the models\n",
    "model = [\n",
    "    ('K-Nearest_Neighbors', KNeighborsClassifier(n_neighbors=5)),  \n",
    "    ('Logistic_Regression', LogisticRegression(random_state=42)),  \n",
    "    ('Support_Vector_Machine', SVC(random_state=42)),  \n",
    "    ('Decision_Tree', DecisionTreeClassifier(random_state=42)),  \n",
    "    ('Random_Forest', RandomForestClassifier(random_state=42)),  \n",
    "    ('Gradient_Boosting', GradientBoostingClassifier(random_state=42)),  \n",
    "]\n",
    "\n",
    "all_balanced_pipelines = {}\n",
    "\n",
    "# All confusion matrix\n",
    "all_confusion_matrix =  {}\n",
    "\n",
    "#Create a DataFrame for the metrics\n",
    "balanced_metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "#Train and evaluate each model\n",
    "for model_name, classifier in model:\n",
    "    \n",
    "    #Create pipeline\n",
    "    balanced_pipeline = imbpipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42, k_neighbors=15, sampling_strategy='auto')),\n",
    "        ('feature_selection', SelectKBest(mutual_info_classif, k='all')),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    #Fit data to pipeline\n",
    "    balanced_pipeline.fit(X_train, y_train_encoded)\n",
    "    all_balanced_pipelines[model_name] = balanced_pipeline\n",
    "\n",
    "    #Make predictions on the test set\n",
    "    y_pred = balanced_pipeline.predict(X_eval)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix_imb = confusion_matrix(y_eval_encoded, y_pred)\n",
    "\n",
    "    all_confusion_matrix[model_name] = confusion_matrix_imb\n",
    "\n",
    "    #Generate classification report for each model\n",
    "    balanced_metrics = classification_report(y_eval_encoded, y_pred, output_dict=True)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    balanced_accuracy = balanced_metrics['accuracy']\n",
    "    balanced_precision = balanced_metrics['weighted avg']['precision']\n",
    "    balanced_recall = balanced_metrics['weighted avg']['recall']\n",
    "    balanced_f1_score= balanced_metrics['weighted avg']['f1-score']\n",
    "\n",
    "    #Add metrics to metrics_output\n",
    "    balanced_metrics_output.loc[len(balanced_metrics_output)] = [model_name, balanced_accuracy, balanced_precision, balanced_recall, balanced_f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Display the metrics_output\n",
    "balanced_metrics_output.sort_values(ascending=False, by='f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Plot the distribution of the target variable before and after oversampling\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='churn', data=df, palette='coolwarm')\n",
    "plt.title('Distribution of Churn Before Oversampling')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=y_train_encoded, palette='coolwarm')\n",
    "plt.title('Distribution of Churn After Oversampling')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelling the Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is the reults of the performance of the models after balancing the dataset.\n",
    "* Gradient Boosting has the highest accuracy, precision, recall, and F1 score among the models listed, followed closely by Logistic Regression and Random Forest.\n",
    "\n",
    "* Support Vector Machine and K-Nearest Neighbors have relatively lower accuracy, precision, recall, and F1 score compared to other models, indicating lower performance.\n",
    "\n",
    "* Decision Tree has slightly better performance than Support Vector Machine and K-Nearest Neighbors but is still outperformed by Gradient Boosting, Logistic Regression, and Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying feature selection to improve performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gradient Boosting still has the highest accuracy, precision, recall, and F1 score among the models listed, followed closely by Logistic Regression and Random Forest.\n",
    "\n",
    "* Support Vector Machine and K-Nearest Neighbors still have relatively lower accuracy, precision, recall, and F1 score compared to other models, indicating lower performance.\n",
    "\n",
    "* Decision Tree has slightly better performance than Support Vector Machine and K-Nearest Neighbors but is still outperformed by Gradient Boosting, Logistic Regression, and Random Forest.\n",
    "\n",
    "* Overall, the interpretation remains similar to the previous results, indicating that feature selection did not significantly alter the model performance rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding confusion matrix to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Iterate over the keys (model names) in the all_confusion_matrix dictionary\n",
    "for model_name, confusion_matrix in all_confusion_matrix.items():\n",
    "    print(f\"Confusion Matrix for {model_name}:\")\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Plot confusion matrices using heatmaps\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, (model, confusion_matrix_imb) in enumerate(all_confusion_matrix.items()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    sns.heatmap(confusion_matrix_imb, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_title(f\"Confusion Matrix for {model}\")\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The best performing models are typically those with high TP and TN rates and low FP and FN rates. For the purpose of this project, we will use the same metrics in selecting the best model. \n",
    "* Looking at this confusion matrice, based on the TP and TN rates, the best performing models are Random Forest and Gradient Boosting as they have the highest TP and TN rates among the models. \n",
    "* For FP and FN rates, the lower the values, the better the model. Hence, the models with the lowest FP and FN rates are also Random Forest and Gradient Boosting. They achieve a good balance between correctly identifying positive cases (churn) and correctly identifying negative cases (non-churn).\n",
    "* Therefore, Random Forest and Gradient Boosting can be considered the best performing models based on both TP and TN rates, as well as FP and FN rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize Evaluation Using ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define the models\n",
    "model = [\n",
    "    ('K-Nearest_Neighbors', KNeighborsClassifier(n_neighbors=5)),  \n",
    "    ('Logistic_Regression', LogisticRegression(random_state=42)),  \n",
    "    ('Support_Vector_Machine', SVC(random_state=42, probability=True)),  # Set probability=True\n",
    "    ('Decision_Tree', DecisionTreeClassifier(random_state=42)),  \n",
    "    ('Random_Forest', RandomForestClassifier(random_state=42)),  \n",
    "    ('Gradient_Boosting', GradientBoostingClassifier(random_state=42)),  \n",
    "]\n",
    "\n",
    "all_balanced_pipelines = {}\n",
    "\n",
    "# Create a DataFrame for the metrics\n",
    "balanced_metrics_output = pd.DataFrame(columns=['model_name', 'accuracy', 'precision', 'recall', 'f1_score'])\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, classifier in model:\n",
    "    \n",
    "    # Create pipeline with feature selection\n",
    "    balanced_pipeline = imbpipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', SelectKBest(score_func=f_classif, k=10)),  # Selecting top 10 features based on ANOVA F-value\n",
    "        ('smote', SMOTE(random_state=42, k_neighbors=15, sampling_strategy='auto')),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    # Fit data to pipeline\n",
    "    balanced_pipeline.fit(X_train, y_train_encoded)\n",
    "    all_balanced_pipelines[model_name] = balanced_pipeline\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = balanced_pipeline.predict(X_eval)\n",
    "\n",
    "    # Generate classification report for each model\n",
    "    balanced_metrics = classification_report(y_eval_encoded, y_pred, output_dict=True)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    balanced_accuracy = balanced_metrics['accuracy']\n",
    "    balanced_precision = balanced_metrics['weighted avg']['precision']\n",
    "    balanced_recall = balanced_metrics['weighted avg']['recall']\n",
    "    balanced_f1_score= balanced_metrics['weighted avg']['f1-score']\n",
    "\n",
    "    # Add metrics to metrics_output\n",
    "    balanced_metrics_output.loc[len(balanced_metrics_output)] = [model_name, balanced_accuracy, balanced_precision, balanced_recall, balanced_f1_score]\n",
    "\n",
    "# Plot roc_curves\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "all_roc_data = {}\n",
    "\n",
    "for model_name, balanced_pipeline in all_balanced_pipelines.items():\n",
    "\n",
    "    y_score = balanced_pipeline.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_eval_encoded, y_score)\n",
    "    \n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    roc_data = pd.DataFrame({'False Positive Rate': fpr, 'True Positive Rate': tpr, 'Threshold': thresholds})\n",
    "\n",
    "    all_roc_data[model_name] = roc_data\n",
    "\n",
    "    ax.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc})')\n",
    "\n",
    "    ax.plot([0,1], [0,1])\n",
    "\n",
    "    ax.set_ylabel('False Positive Rate')\n",
    "    \n",
    "    ax.set_xlabel('True Positive Rate')\n",
    "\n",
    "\n",
    "ax.set_title('ROC Curve Plot for all Pipelines')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on the provided AUC (Area Under the ROC Curve) values, the best performing models are;\n",
    "1. Gradient Boosting\n",
    "2. Logistic Regression\n",
    "3. Support Vector Machine\n",
    "* These models have higher AUC values, indicating better overall performance in terms of the trade-off between true positive rate and false positive rate.\n",
    "* We will select Gradient Boosting and Logistic Regression as the best performing models, and perform threshold optimization on these tow models as well as hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Preview of the threshold for Logistic Regression\n",
    "all_roc_data['Logistic_Regression'].loc[340:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Preview of the threshold for Gradient Boosting\n",
    "all_roc_data['Gradient_Boosting'].loc[340:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Preview the Gradient Boosting pipeline\n",
    "GradientBoostingClassifier_pipeline = all_balanced_pipelines['Gradient_Boosting']\n",
    "GradientBoostingClassifier_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Best threshold\n",
    "gradient_threshold = 0.25\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = GradientBoostingClassifier_pipeline.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "# Make predictions based on the threshold\n",
    "predictions = (y_pred_proba > gradient_threshold).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "gradient_threshold_matrix = confusion_matrix(y_eval_encoded, predictions)\n",
    "\n",
    "# Saving the best model and threshold in variables\n",
    "best_gradient_boosting_model = GradientBoostingClassifier_pipeline\n",
    "best_gradient_threshold = gradient_threshold\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(gradient_threshold_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(gradient_threshold_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Gradient Boosting')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Preview the logistic regression pipeline\n",
    "LogisticRegression_pipeline = all_balanced_pipelines['Logistic_Regression']\n",
    "LogisticRegression_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Best threshold\n",
    "LR_threshold = 0.22\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = LogisticRegression_pipeline.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "# Make predictions based on the threshold\n",
    "predictions = (y_pred_proba > LR_threshold).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "LR_threshold_matrix = confusion_matrix(y_eval_encoded, predictions)\n",
    "\n",
    "# Saving the best model and threshold in variables\n",
    "best_logistic_regression_model = LogisticRegression_pipeline\n",
    "best_LR_threshold = LR_threshold\n",
    "LR_threshold_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(LR_threshold_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HYPERPARAMETER TUNING TO IMPROVE MODEL PERFORMANCE\n",
    "* We will perform hyperparameter tuning on the two best performing models to improve their performance thus Gradient Boosting and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyper tuning Gradient Boosting Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Load the saved GradientBoostingClassifier pipeline\n",
    "current_params = best_gradient_boosting_model.get_params()\n",
    "current_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#Define parameters\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],\n",
    "    'classifier__learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
    "    'classifier__max_depth': [3, 5, 7, 10],\n",
    "    'classifier__subsample': [0.8, 0.9, 1.0],\n",
    "    'classifier__min_samples_split': [2, 3, 5, 8, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 3, 4, 8],\n",
    "    'classifier__max_features': ['sqrt', 'log2'],\n",
    "    'classifier__criterion': ['friedman_mse', 'squared_error'],\n",
    "    'classifier__min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "    'classifier__ccp_alpha': [0.0, 0.1, 0.2],\n",
    "    'preprocessor__numerical_pipeline__numerical_imputer__strategy': ['mean', 'median'],\n",
    "    'preprocessor__categorical_pipeline__categorical_imputer__strategy': ['most_frequent', 'constant'],\n",
    "    'preprocessor__categorical_pipeline__encoder__handle_unknown': ['error', 'ignore']\n",
    "}\n",
    "\n",
    "#Initialize RandomizedSearchCV\n",
    "random_search_gb = RandomizedSearchCV(estimator=best_gradient_boosting_model, param_distributions=param_grid, scoring='accuracy',\n",
    "                                      cv=5, n_jobs=-1, n_iter=150, random_state=42, verbose=2)\n",
    "\n",
    "#Fit the randomized search on the train data\n",
    "random_search_gb.fit(X_train, y_train_encoded)\n",
    "\n",
    "#Best parameters\n",
    "best_params = random_search_gb.best_params_\n",
    "\n",
    "#Mean accuracy score of the best estimator\n",
    "best_score = random_search_gb.best_score_\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Display the best score\n",
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating the performance of the tuned model compared to the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "#Fit tuned model on train data\n",
    "tuned_gb_model = random_search_gb.best_estimator_\n",
    "tuned_gb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "#Make predictions\n",
    "random_search_gb_pred = tuned_gb_model.predict(X_eval)\n",
    "original_gb_pred = best_gradient_boosting_model.predict(X_eval)\n",
    "\n",
    "#Evaluate performance\n",
    "random_search_gb_accuracy = accuracy_score(y_eval_encoded, random_search_gb_pred)\n",
    "original_gb_accuracy = accuracy_score(y_eval_encoded, original_gb_pred)\n",
    "\n",
    "random_search_gb_precision = precision_score(y_eval_encoded, random_search_gb_pred)\n",
    "original_gb_precision = precision_score(y_eval_encoded, original_gb_pred)\n",
    "\n",
    "random_search_gb_recall = recall_score(y_eval_encoded, random_search_gb_pred)\n",
    "original_gb_recall = recall_score(y_eval_encoded, original_gb_pred)\n",
    "\n",
    "random_search_gb_f1 = f1_score(y_eval_encoded, random_search_gb_pred)\n",
    "original_gb_f1 = f1_score(y_eval_encoded, original_gb_pred)\n",
    "\n",
    "#Print comparison\n",
    "print(\"Randomized Search Tuned Model:\")\n",
    "print(f\"Accuracy: {random_search_gb_accuracy:.4f}\")\n",
    "print(f\"Precision: {random_search_gb_precision:.4f}\")\n",
    "print(f\"Recall: {random_search_gb_recall:.4f}\")\n",
    "print(f\"F1-score: {random_search_gb_f1:.4f}\")\n",
    "print(\"\\nOriginal Model:\")\n",
    "print(f\"Accuracy: {original_gb_accuracy:.4f}\")\n",
    "print(f\"Precision: {original_gb_precision:.4f}\")\n",
    "print(f\"Recall: {original_gb_recall:.4f}\")\n",
    "print(f\"F1-score: {original_gb_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on this output, the original model has a higher accuracy, precision, recall, and F1-score compared to the tuned model but it's essential to consider the trade-offs between these metrics based on the specific objectives of the Business. The original model performs better in capturing actual positive instances but might have lower precision. On the other hand, the tuned model achieves a better balance between precision and recall, which is preferable for the Business objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the tuned Gradient Boosting model to make predictions on the Evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gradient_threshold = 0.25\n",
    "\n",
    "#Make predictions on the test set\n",
    "y_pred_proba = tuned_gb_model.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "#Apply the specified threshold to convert probabilities to binary predictions\n",
    "predictions_GB = (y_pred_proba > best_gradient_threshold).astype(int)\n",
    "\n",
    "#Compute the confusion matrix\n",
    "threshold_matrix = confusion_matrix(y_eval_encoded, predictions_GB)\n",
    "print(threshold_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(threshold_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Tuned Gradient Boosting Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "current_params = best_logistic_regression_model.get_params()\n",
    "current_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_LR = GridSearchCV(best_logistic_regression_model, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# The training set\n",
    "grid_search_LR.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters: \", grid_search_LR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Best score\n",
    "grid_search_LR.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_model_LR = grid_search_LR.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_proba = best_model_LR.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "# Apply the specified threshold to convert probabilities to binary predictions\n",
    "predictions = (y_pred_proba > LR_threshold).astype(int)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "threshold_matrix_LR = confusion_matrix(y_eval_encoded, predictions)\n",
    "print(threshold_matrix_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(threshold_matrix_LR, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Tuned Linear Regression Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BUSINESS IMPACT ASSESSMENT\n",
    "##### Business Objective\n",
    "The main objective of the business is to create a predictive model that improves true positives and reduces the occurrence of false negatives. Specifically, in the case of customer churn prediction, a false negative arises when the model inaccurately forecasts that a customer will not churn, whereas they indeed do. This error could lead to missed chances to take action and retain valuable customers.\n",
    "##### Optimal Model Selection\n",
    "Due to the paramount importance of reducing false negatives, the ideal choice for best model is the model that shows the fewest occurrences of false negatives. In our assessment, the Logistic Regression model has proven to excel in this aspect. The decrease in false negatives indicates an enhanced ability to recognize customers prone to churn, aligning closely with our key business objectives.\n",
    "##### Conclusion\n",
    "In conclusion, the Logistic Regression model emerges as the top choice for our churn prediction task, emphasizing the minimization of false negatives. Adopting this model empowers businesses to preemptively pinpoint and retain customers prone to churning, ultimately bolstering customer retention rates, optimizing revenue, and securing enduring business viability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the Model on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Load the test data\n",
    "test_data = pd.read_csv(\"Dataset\\Telco-churn-last-2000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Preview the test data\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the cells\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert Totalcharges column to numeric\n",
    "test_data['TotalCharges'] = pd.to_numeric(test_data['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_data['TotalCharges'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert SeniorCitizen column to object\n",
    "test_data['SeniorCitizen'] = test_data['SeniorCitizen'].replace({0:'No', 1:'Yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Drop the customerID column\n",
    "test_data.drop('customerID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check dataframe\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Convert column names to lower case\n",
    "test_data.columns = test_data.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Check the totalcharges column\n",
    "test_data[test_data['totalcharges']== '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "empty_totalcharges = test_data[test_data['totalcharges'].isna()]\n",
    "empty_totalcharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Replace the NaN values with 0\n",
    "test_data['totalcharges'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "empty_totalcharges = test_data[test_data['totalcharges'].isna()]\n",
    "empty_totalcharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "4#Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Get categorical columns\n",
    "num_columns = test_data.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Fit and transform on training data\n",
    "train_encoded = encoder.fit_transform(test_data[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Make Predictions on the test data\n",
    "predictions = best_model_LR.predict(test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pipeline_predictions = LogisticRegression_pipeline.predict(test_data)\n",
    "pipeline_predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#Predictions\n",
    "decoded_predictions = encoder.inverse_transform(predictions_reshaped)\n",
    "decoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
